{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/greek_gods_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_name_to_syllabes(name):\n",
    "    voyelles = \"aeiouy\"\n",
    "    syllabes = []\n",
    "    syllabe = \"\"\n",
    "\n",
    "    for i, char in enumerate(name.lower()):\n",
    "        syllabe += char\n",
    "        if char in voyelles:\n",
    "            if i + 1 == len(name) or name[i + 1].lower() not in voyelles:\n",
    "                syllabes.append(syllabe)\n",
    "                syllabe = \"\" \n",
    "\n",
    "    if syllabe:\n",
    "        syllabes.append(syllabe)\n",
    "\n",
    "    return syllabes\n",
    "\n",
    "df['tokens'] = df['name_english'].apply(cut_name_to_syllabes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def syllables_to_string(tokens):\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df['tokens_str'] = df['tokens'].apply(syllables_to_string)\n",
    "\n",
    "X = df['tokens_str'] \n",
    "y = df['main_type']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    ('Random Forest', RandomForestClassifier(n_estimators=500, random_state=42)),\n",
    "    ('SVM', SVC(random_state=42)),\n",
    "    ('Logistic Regression', LogisticRegression(random_state=42)),\n",
    "    ('Naive Bayes', MultinomialNB())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_count = CountVectorizer()\n",
    "X_train_vec_count = vectorizer_count.fit_transform(X_train)\n",
    "X_test_vec_count = vectorizer_count.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_tfidf = TfidfVectorizer()\n",
    "X_train_vec_tfidf = vectorizer_tfidf.fit_transform(X_train)\n",
    "X_test_vec_tfidf = vectorizer_tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(X_train_vec, X_test_vec, model):\n",
    "    model.fit(X_train_vec, y_train)\n",
    "    y_pred = model.predict(X_test_vec)\n",
    "    return accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer\n",
      "model : Random Forest => 0.6567164179104478\n",
      "model : SVM => 0.6791044776119403\n",
      "model : Logistic Regression => 0.6940298507462687\n",
      "model : Naive Bayes => 0.6940298507462687\n",
      "--------------------------------\n",
      "Tfidf\n",
      "model : Random Forest => 0.5895522388059702\n",
      "model : SVM => 0.6791044776119403\n",
      "model : Logistic Regression => 0.6791044776119403\n",
      "model : Naive Bayes => 0.6865671641791045\n"
     ]
    }
   ],
   "source": [
    "print(\"CountVectorizer\")\n",
    "for name, model in models:\n",
    "     print(f\"model : {name} => \" + str(evaluate_model(X_train_vec_count, X_test_vec_count, model)))\n",
    "\n",
    "print('--------------------------------')\n",
    "print(\"Tfidf\")\n",
    "for name, model in models:\n",
    "    print(f\"model : {name} => \" + str(evaluate_model(X_train_vec_tfidf, X_test_vec_tfidf, model)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Le tf idf a des scores globalement inferieur au CountVectorizer.\n",
    "Avec RandomForest n= 100 , on a \n",
    "\n",
    "CountVectorizer \n",
    "model : Random Forest => 0.6417910447761194 \n",
    "----\n",
    "Tfidf\n",
    "model : Random Forest => 0.6044776119402985\n",
    "\n",
    "---\n",
    "\n",
    "Et avec n=500 : \n",
    "\n",
    "CountVectorizer\n",
    "model : Random Forest => 0.6567164179104478\n",
    "----\n",
    "Tfidf\n",
    "model : Random Forest => 0.5895522388059702\n",
    "\n",
    "Le paramètre n_estimators améliore légèrement la performance quand le RandomForest est utilisé avec CountVectorizer, par rapport à TF-IDF où la performance diminue \n",
    "'''\n",
    "''' \n",
    "Pour le moment, le meilleurs modèle est la régression logistique avec CountVectorizer\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logistic_regression_trained(df, test_size=0.3, random_state=42):\n",
    "    X = df['tokens_str'] \n",
    "    y = df['main_type']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    vectorizer = CountVectorizer()\n",
    "    \n",
    "    X_train_vec = vectorizer.fit_transform(X_train)\n",
    "    X_test_vec = vectorizer.transform(X_test)\n",
    "    \n",
    "    model = LogisticRegression(random_state=random_state)\n",
    "    model.fit(X_train_vec, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test_vec)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return model, vectorizer, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "Probabilités pour chaque classe : [0.26397143 0.70372833 0.03230024]\n",
      "Classe prédite : personification, Score : 0.7037\n",
      "-------------------\n",
      "Probabilités pour chaque classe : [0.36334797 0.54744747 0.08920456]\n",
      "Classe prédite : personification, Score : 0.5474\n",
      "-------------------\n",
      "Probabilités pour chaque classe : [0.26397143 0.70372833 0.03230024]\n",
      "Classe prédite : personification, Score : 0.7037\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def test_prediction(nom, model, vectorizer):\n",
    "    syllabes = cut_name_to_syllabes(nom)\n",
    "    \n",
    "    name_str = syllables_to_string(syllabes)\n",
    "    \n",
    "    name_vec = vectorizer.transform([name_str])\n",
    "    \n",
    "    probas = model.predict_proba(name_vec)\n",
    "    \n",
    "    print(f\"Probabilités pour chaque classe : {probas[0]}\")\n",
    "    \n",
    "    pred = model.classes_[probas.argmax()]\n",
    "    score = probas.max() \n",
    "\n",
    "    return pred, score\n",
    "\n",
    "tests_name = [\n",
    "    \"Deimos\",\n",
    "    \"Mideimos\",\n",
    "    \"Deimosmi\"\n",
    "]\n",
    "\n",
    "model_lr, vectorizer_lr, accuracy_lr = get_logistic_regression_trained(df)\n",
    "print(\"-------------------\")\n",
    "for name in tests_name:\n",
    "    classe, score = test_prediction(name, model_lr, vectorizer_lr)\n",
    "    print(f\"Classe prédite : {classe}, Score : {score:.4f}\")\n",
    "    print(\"-------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" les résultats sont cohérents, et seront suffisant pour ce que l'on désire obtenir, concernant le main_type\\nMaintenant, on peut regarder le cas du sub_type.\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' les résultats sont cohérents, et seront suffisant pour ce que l'on désire obtenir, concernant le main_type\n",
    "Maintenant, on peut regarder le cas du sub_type.\n",
    "La logique est la même que pour le main_type.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Sub_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def syllables_to_string(tokens):\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df['tokens_str'] = df['tokens'].apply(syllables_to_string)\n",
    "\n",
    "X = df['tokens_str'] \n",
    "y = df['sub_type']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer\n",
      "model : Random Forest => 0.5522388059701493\n",
      "model : SVM => 0.582089552238806\n",
      "model : Logistic Regression => 0.5970149253731343\n",
      "model : Naive Bayes => 0.6044776119402985\n",
      "--------------------------------\n",
      "Tfidf\n",
      "model : Random Forest => 0.5149253731343284\n",
      "model : SVM => 0.5895522388059702\n",
      "model : Logistic Regression => 0.5970149253731343\n",
      "model : Naive Bayes => 0.6044776119402985\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    ('Random Forest', RandomForestClassifier(n_estimators=500, random_state=42)),\n",
    "    ('SVM', SVC(random_state=42)),\n",
    "    ('Logistic Regression', LogisticRegression(random_state=42)),\n",
    "    ('Naive Bayes', MultinomialNB())\n",
    "]\n",
    "vectorizer_count = CountVectorizer()\n",
    "X_train_vec_count = vectorizer_count.fit_transform(X_train)\n",
    "X_test_vec_count = vectorizer_count.transform(X_test)\n",
    "\n",
    "vectorizer_tfidf = TfidfVectorizer()\n",
    "X_train_vec_tfidf = vectorizer_tfidf.fit_transform(X_train)\n",
    "X_test_vec_tfidf = vectorizer_tfidf.transform(X_test)\n",
    "\n",
    "def evaluate_model(X_train_vec, X_test_vec, model):\n",
    "    model.fit(X_train_vec, y_train)\n",
    "    y_pred = model.predict(X_test_vec)\n",
    "    return accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"CountVectorizer\")\n",
    "for name, model in models:\n",
    "     print(f\"model : {name} => \" + str(evaluate_model(X_train_vec_count, X_test_vec_count, model)))\n",
    "\n",
    "print('--------------------------------')\n",
    "print(\"Tfidf\")\n",
    "for name, model in models:\n",
    "    print(f\"model : {name} => \" + str(evaluate_model(X_train_vec_tfidf, X_test_vec_tfidf, model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Les résultats sont plutôt mauvais : 1 chance sur 2 que la prédiction soit juste.\n",
    "On va essayer de modifier les hyper paramètres pour chaque modèle pour améliorer ça. L'idéal serait au moins 75% de réussite\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model : Random Forest - Count - 1 => 0.5746268656716418\n",
      "model : Random Forest - Tfidf - 1 =>0.5671641791044776\n",
      "model : Random Forest - Count - 2 => 0.5522388059701493\n",
      "model : Random Forest - Tfidf - 2 =>0.5447761194029851\n",
      "model : Random Forest - Count - 3 => 0.5447761194029851\n",
      "model : Random Forest - Tfidf - 3 =>0.5149253731343284\n",
      "model : Random Forest - Count - 4 => 0.5447761194029851\n",
      "model : Random Forest - Tfidf - 4 =>0.5074626865671642\n",
      "model : Random Forest - Count - 5 => 0.5447761194029851\n",
      "model : Random Forest - Tfidf - 5 =>0.5223880597014925\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,6):\n",
    "\n",
    "    rf = RandomForestClassifier(n_estimators=300*i, max_depth=20*i, random_state=42)\n",
    "    print(f\"model : Random Forest - Count - {i} => \" + str(evaluate_model(X_train_vec_count, X_test_vec_count, rf)))\n",
    "    print(f\"model : Random Forest - Tfidf - {i} => \" + str(evaluate_model(X_train_vec_tfidf, X_test_vec_tfidf, rf)))\n",
    "    \n",
    "# c'est clairement mieux dans le cas de TF-IDF ( +5%) mais reste plutôt bas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model : SVM - Count - 1 => 0.5746268656716418\n",
      "model : SVM - Tfidf - 1 => 0.5746268656716418\n",
      "model : SVM - Count - 2 => 0.5671641791044776\n",
      "model : SVM - Tfidf - 2 => 0.5597014925373134\n",
      "model : SVM - Count - 3 => 0.5522388059701493\n",
      "model : SVM - Tfidf - 3 => 0.5522388059701493\n",
      "model : SVM - Count - 4 => 0.5223880597014925\n",
      "model : SVM - Tfidf - 4 => 0.5298507462686567\n",
      "model : SVM - Count - 5 => 0.5\n",
      "model : SVM - Tfidf - 5 => 0.5298507462686567\n",
      "----------------------- Normalized : \n",
      "model : SVM - Count - 1 => 0.35074626865671643\n",
      "model : SVM - Tfidf - 1 => 0.39552238805970147\n",
      "model : SVM - Count - 2 => 0.35074626865671643\n",
      "model : SVM - Tfidf - 2 => 0.39552238805970147\n",
      "model : SVM - Count - 3 => 0.35074626865671643\n",
      "model : SVM - Tfidf - 3 => 0.39552238805970147\n",
      "model : SVM - Count - 4 => 0.35074626865671643\n",
      "model : SVM - Tfidf - 4 => 0.39552238805970147\n",
      "model : SVM - Count - 5 => 0.35074626865671643\n",
      "model : SVM - Tfidf - 5 => 0.39552238805970147\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "for i in range(1,6):\n",
    "    svm = SVC(C=i, kernel='linear', random_state=42 * i)\n",
    "    print(f\"model : SVM - Count - {i} => \" + str(evaluate_model(X_train_vec_count, X_test_vec_count, svm)))\n",
    "    print(f\"model : SVM - Tfidf - {i} => \" + str(evaluate_model(X_train_vec_tfidf, X_test_vec_tfidf, svm)))\n",
    "\n",
    "# c'est pire qu'avant\n",
    "\n",
    "# on peut egalement essayer de normaliser les données\n",
    "\n",
    "scaler = StandardScaler(with_mean=False)  \n",
    "X_train_normalized_tfidf = scaler.fit_transform(X_train_vec_tfidf)  \n",
    "X_test_normalized_tfidf = scaler.transform(X_test_vec_tfidf)\n",
    " \n",
    "X_train_normalized_count = scaler.fit_transform(X_train_vec_count)  \n",
    "X_test_normalized_count = scaler.transform(X_test_vec_count)\n",
    "\n",
    "print(\"----------------------- Normalized : \")\n",
    "for i in range(1,6):\n",
    "    svm = SVC(C=i, kernel='linear', random_state=42 * i)\n",
    "    print(f\"model : SVM - Count - {i} => \" + str(evaluate_model(X_train_normalized_count, X_test_normalized_count, svm)))\n",
    "    print(f\"model : SVM - Tfidf - {i} => \" + str(evaluate_model(X_train_normalized_tfidf, X_test_normalized_tfidf, svm)))\n",
    "\n",
    "# c'est encore pire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model : Lg - Count - 1 => 0.6194029850746269\n",
      "model : Lg - Tfidf - 1 => 0.5970149253731343\n",
      "model : Lg - Count - 2 => 0.6194029850746269\n",
      "model : Lg - Tfidf - 2 => 0.5970149253731343\n",
      "model : Lg - Count - 3 => 0.6194029850746269\n",
      "model : Lg - Tfidf - 3 => 0.5970149253731343\n",
      "model : Lg - Count - 4 => 0.6194029850746269\n",
      "model : Lg - Tfidf - 4 => 0.5970149253731343\n",
      "model : Lg - Count - 5 => 0.6194029850746269\n",
      "model : Lg - Tfidf - 5 => 0.5970149253731343\n",
      "----------------------- Normalized : \n",
      "model : Lg - Count - 1 => 0.5074626865671642\n",
      "model : Lg - Tfidf - 1 => 0.4925373134328358\n",
      "model : Lg - Count - 2 => 0.5074626865671642\n",
      "model : Lg - Tfidf - 2 => 0.4925373134328358\n",
      "model : Lg - Count - 3 => 0.5074626865671642\n",
      "model : Lg - Tfidf - 3 => 0.4925373134328358\n",
      "model : Lg - Count - 4 => 0.5074626865671642\n",
      "model : Lg - Tfidf - 4 => 0.4925373134328358\n",
      "model : Lg - Count - 5 => 0.5074626865671642\n",
      "model : Lg - Tfidf - 5 => 0.4925373134328358\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,6):\n",
    "    lg = LogisticRegression(max_iter=25*i, solver='liblinear', random_state=42)\n",
    "    print(f\"model : Lg - Count - {i} => \" + str(evaluate_model(X_train_vec_count, X_test_vec_count, lg)))\n",
    "    print(f\"model : Lg - Tfidf - {i} => \" + str(evaluate_model(X_train_vec_tfidf, X_test_vec_tfidf, lg)))\n",
    "# les resultats sont identiques, cela signifie qu'on pourra pas améliorer ce modèle avec les hyperparamètres généraux.\n",
    "\n",
    "print(\"----------------------- Normalized : \")\n",
    "for i in range(1,6):\n",
    "    lg = LogisticRegression(max_iter=25*i, solver='liblinear', random_state=42)\n",
    "    print(f\"model : Lg - Count - {i} => \" + str(evaluate_model(X_train_normalized_count, X_test_normalized_count, lg)))\n",
    "    print(f\"model : Lg - Tfidf - {i} => \" + str(evaluate_model(X_train_normalized_tfidf, X_test_normalized_tfidf, lg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model : Nb - Count - 1 => 0.582089552238806\n",
      "model : Nb - Tfidf - 1 => 0.5970149253731343\n",
      "model : Nb - Count - 2 => 0.6044776119402985\n",
      "model : Nb - Tfidf - 2 => 0.5970149253731343\n",
      "model : Nb - Count - 3 => 0.5970149253731343\n",
      "model : Nb - Tfidf - 3 => 0.5970149253731343\n",
      "model : Nb - Count - 4 => 0.6044776119402985\n",
      "model : Nb - Tfidf - 4 => 0.6119402985074627\n",
      "model : Nb - Count - 5 => 0.6044776119402985\n",
      "model : Nb - Tfidf - 5 => 0.6119402985074627\n",
      "model : Nb - Count - 6 => 0.5970149253731343\n",
      "model : Nb - Tfidf - 6 => 0.6044776119402985\n",
      "model : Nb - Count - 7 => 0.5895522388059702\n",
      "model : Nb - Tfidf - 7 => 0.6044776119402985\n",
      "model : Nb - Count - 8 => 0.5895522388059702\n",
      "model : Nb - Tfidf - 8 => 0.6119402985074627\n",
      "model : Nb - Count - 9 => 0.5895522388059702\n",
      "model : Nb - Tfidf - 9 => 0.6194029850746269\n",
      "model : Nb - Count - 10 => 0.6044776119402985\n",
      "model : Nb - Tfidf - 10 => 0.6044776119402985\n",
      "----------------------- Normalized : \n",
      "model : Nb - Count - 1 => 0.4253731343283582\n",
      "model : Nb - Tfidf - 1 => 0.4253731343283582\n",
      "model : Nb - Count - 2 => 0.417910447761194\n",
      "model : Nb - Tfidf - 2 => 0.4253731343283582\n",
      "model : Nb - Count - 3 => 0.417910447761194\n",
      "model : Nb - Tfidf - 3 => 0.4253731343283582\n",
      "model : Nb - Count - 4 => 0.41044776119402987\n",
      "model : Nb - Tfidf - 4 => 0.43283582089552236\n",
      "model : Nb - Count - 5 => 0.40298507462686567\n",
      "model : Nb - Tfidf - 5 => 0.417910447761194\n",
      "model : Nb - Count - 6 => 0.40298507462686567\n",
      "model : Nb - Tfidf - 6 => 0.41044776119402987\n",
      "model : Nb - Count - 7 => 0.417910447761194\n",
      "model : Nb - Tfidf - 7 => 0.41044776119402987\n",
      "model : Nb - Count - 8 => 0.4253731343283582\n",
      "model : Nb - Tfidf - 8 => 0.417910447761194\n",
      "model : Nb - Count - 9 => 0.4253731343283582\n",
      "model : Nb - Tfidf - 9 => 0.41044776119402987\n",
      "model : Nb - Count - 10 => 0.44776119402985076\n",
      "model : Nb - Tfidf - 10 => 0.41044776119402987\n"
     ]
    }
   ],
   "source": [
    "MultinomialNB(alpha=0.7)\n",
    "for i in range(1,11):\n",
    "    nb = MultinomialNB(alpha=0.1 * i)\n",
    "    print(f\"model : Nb - Count - {i} => \" + str(evaluate_model(X_train_vec_count, X_test_vec_count, nb)))\n",
    "    print(f\"model : Nb - Tfidf - {i} => \" + str(evaluate_model(X_train_vec_tfidf, X_test_vec_tfidf, nb)))\n",
    "# l'impact de alpha n'est pas significatif\n",
    "\n",
    "print(\"----------------------- Normalized : \")\n",
    "for i in range(1,11):\n",
    "    nb = MultinomialNB(alpha=0.1 * i)\n",
    "    print(f\"model : Nb - Count - {i} => \" + str(evaluate_model(X_train_normalized_count, X_test_normalized_count, nb)))\n",
    "    print(f\"model : Nb - Tfidf - {i} => \" + str(evaluate_model(X_train_normalized_tfidf, X_test_normalized_tfidf, nb)))\n",
    "\n",
    "# avec les données normalisées, les performances sont pires\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Puisque rien n'est mieux, nous resterons sur le CountVectorizer -  Naive Bayes, sans normalisation, avec son 60% de performance.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_naive_bayes_trained(df, test_size=0.3, random_state=42):\n",
    "    X = df['tokens_str'] \n",
    "    y = df['sub_type']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    vectorizer = CountVectorizer()\n",
    "    \n",
    "    X_train_vec = vectorizer.fit_transform(X_train)\n",
    "    X_test_vec = vectorizer.transform(X_test)\n",
    "    \n",
    "    model = MultinomialNB()\n",
    "    model.fit(X_train_vec, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test_vec)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return model, vectorizer, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "['god' 'major' 'olympian' 'other' 'personification' 'primordial']\n",
      "Probabilités pour chaque classe : [0.75004988 0.01623824 0.01442017 0.02301947 0.18419941 0.01207283]\n",
      "Classe prédite : god, Score : 0.7500\n",
      "-------------------\n",
      "['god' 'major' 'olympian' 'other' 'personification' 'primordial']\n",
      "Probabilités pour chaque classe : [0.37965052 0.04217801 0.01575799 0.02317947 0.52576654 0.01346747]\n",
      "Classe prédite : personification, Score : 0.5258\n",
      "-------------------\n",
      "['god' 'major' 'olympian' 'other' 'personification' 'primordial']\n",
      "Probabilités pour chaque classe : [0.47235996 0.11013754 0.03835099 0.02839645 0.33321338 0.01754167]\n",
      "Classe prédite : god, Score : 0.4724\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "def test_prediction_sub(nom, model, vectorizer):\n",
    "    syllabes = cut_name_to_syllabes(nom)\n",
    "    \n",
    "    name_str = syllables_to_string(syllabes)\n",
    "    \n",
    "    name_vec = vectorizer.transform([name_str])\n",
    "    \n",
    "    probas = model.predict_proba(name_vec)\n",
    "    print(model.classes_)\n",
    "    print(f\"Proba pour chaque classe : {probas[0]}\")\n",
    "    \n",
    "    pred = model.classes_[probas.argmax()]\n",
    "    score = probas.max() \n",
    "\n",
    "    return pred, score\n",
    "\n",
    "tests_name = [\n",
    "    \"Tartarus\",\n",
    "    \"Mideimos\",\n",
    "    \"Tethys\"\n",
    "]\n",
    "\n",
    "model_lr, vectorizer_lr, accuracy_lr = get_naive_bayes_trained(df)\n",
    "print(\"-------------------\")\n",
    "for name in tests_name:\n",
    "    classe, score = test_prediction_sub(name, model_lr, vectorizer_lr)\n",
    "    print(f\"Resultat : {classe}, Score : {score:.4f}\")\n",
    "    print(\"-------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les résultats ne sont vraiment pas très intéressant, mais nous pourrons difficilement avoir mieux, au vu du peu de donnée que l'on a , et de la distributivité entre celles-ci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Generation NLP // Pas fonctionnel car trop peu de données , donc avorté</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "King of the gods, ruler of Mount Olympus, and god of the sky, weather, thunder, lightning, law, order, and justice. He is the youngest son of Cronus and Rhea. He overthrew Cronus and gained the sovereignty of heaven for himself. In art he is depicted as a regal, mature man with a sturdy figure and dark beard. His usual attributes are the royal scepter and the lightning bolt. His sacred animals include the eagle and the bull. His Roman counterpart is Jupiter, also known as Jove.\n",
      "\n",
      "[50, 1, 2, 25, 427, 1, 85, 214, 3, 4, 1, 2, 104, 428, 215, 131, 132, 216, 3, 86, 19, 8, 2, 429, 32, 1, 51, 3, 68, 19, 430, 51, 3, 431, 2, 432, 1, 217, 26, 218, 9, 52, 19, 8, 33, 12, 5, 219, 133, 87, 21, 5, 220, 433, 3, 221, 222, 10, 434, 88, 69, 2, 435, 436, 3, 2, 131, 437, 10, 34, 29, 22, 2, 438, 3, 2, 439, 10, 27, 36, 8, 440, 59, 105, 12, 441]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# on tokenize les entree et sortie du model\n",
    "df[\"description\"] = df[\"description\"].fillna(\"\")\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df[\"description\"])\n",
    "\n",
    "X= tokenizer.texts_to_sequences(df[\"description\"])\n",
    "\n",
    "print(df[\"description\"].iloc[0])\n",
    "print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' zeu', 's']\n",
      "[165, 1]\n"
     ]
    }
   ],
   "source": [
    "tokenizer_tokens = Tokenizer(char_level=False)  \n",
    "tokenizer_tokens.fit_on_texts(df[\"tokens\"]) \n",
    "\n",
    "y = tokenizer_tokens.texts_to_sequences(df[\"tokens\"])\n",
    "\n",
    "\n",
    "print(df[\"tokens\"].iloc[0])\n",
    "print(y[0]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(444, 188)\n",
      "(444, 188)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "maxlen = max(max(len(seq) for seq in X), max(len(seq) for seq in y))\n",
    "y_normalized = pad_sequences(y, maxlen=maxlen, padding=\"post\")\n",
    "X_normalized = pad_sequences(X, maxlen=maxlen, padding=\"post\")\n",
    "print(X_normalized.shape) \n",
    "print(y_normalized.shape) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 188, 300)          448200    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 188, 128)          219648    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 188, 64)           8256      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 188, 405)          26325     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 702,429\n",
      "Trainable params: 702,429\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "# on fait le model lstm\n",
    "vocab_size_desription = len(tokenizer.word_index) + 1 \n",
    "vocab_size_tokens = len(tokenizer_tokens.word_index) + 1\n",
    "\n",
    "embedding_dim = 300 # plus la valeur est grande, plus on peut representer de mots\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=vocab_size_desription, output_dim=embedding_dim, input_length=maxlen),  \n",
    "    LSTM(128, return_sequences=True), \n",
    "    Dense(64, activation=\"relu\"),\n",
    "    Dense(vocab_size_tokens, activation=\"softmax\") \n",
    "])\n",
    "\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12/12 [==============================] - 7s 301ms/step - loss: 5.5018 - accuracy: 0.8052 - val_loss: 3.4580 - val_accuracy: 0.9823\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - 3s 232ms/step - loss: 1.7007 - accuracy: 0.9826 - val_loss: 0.2204 - val_accuracy: 0.9823\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - 3s 235ms/step - loss: 0.1414 - accuracy: 0.9826 - val_loss: 0.1187 - val_accuracy: 0.9823\n",
      "Epoch 4/10\n",
      "12/12 [==============================] - 3s 232ms/step - loss: 0.1137 - accuracy: 0.9826 - val_loss: 0.1192 - val_accuracy: 0.9823\n",
      "Epoch 5/10\n",
      "12/12 [==============================] - 3s 234ms/step - loss: 0.1129 - accuracy: 0.9826 - val_loss: 0.1175 - val_accuracy: 0.9823\n",
      "Epoch 6/10\n",
      "12/12 [==============================] - 3s 248ms/step - loss: 0.1093 - accuracy: 0.9826 - val_loss: 0.1147 - val_accuracy: 0.9823\n",
      "Epoch 7/10\n",
      "12/12 [==============================] - 3s 253ms/step - loss: 0.1060 - accuracy: 0.9826 - val_loss: 0.1130 - val_accuracy: 0.9823\n",
      "Epoch 8/10\n",
      "12/12 [==============================] - 3s 263ms/step - loss: 0.1043 - accuracy: 0.9826 - val_loss: 0.1125 - val_accuracy: 0.9823\n",
      "Epoch 9/10\n",
      "12/12 [==============================] - 3s 252ms/step - loss: 0.1035 - accuracy: 0.9826 - val_loss: 0.1120 - val_accuracy: 0.9823\n",
      "Epoch 10/10\n",
      "12/12 [==============================] - 3s 257ms/step - loss: 0.1026 - accuracy: 0.9826 - val_loss: 0.1117 - val_accuracy: 0.9823\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f0efcbbdd0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y_normalized, test_size=0.2, random_state=42)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 89ms/step - loss: 0.1114 - accuracy: 0.9823\n",
      "Test Loss: 0.11137121170759201\n",
      "Test Accuracy: 0.9823093414306641\n"
     ]
    }
   ],
   "source": [
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss}\")\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "# les resultats sont excellents, on a 98% de precision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "import numpy as np\n",
    "\n",
    "class PredictionLogger(Callback):\n",
    "    def __init__(self, X_val, y_val, tokenizer_tokens):\n",
    "        super(PredictionLogger, self).__init__()\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "        self.tokenizer_tokens = tokenizer_tokens\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        y_pred = self.model.predict(self.X_val)\n",
    "        \n",
    "        predicted_indices = np.argmax(y_pred, axis=-1)\n",
    "\n",
    "        print(f\"\\nEpoch {epoch + 1}:\")\n",
    "        \n",
    "        for i in range(min(5, len(self.X_val))):\n",
    "            pred_word = ''.join([self.tokenizer_tokens.index_word[idx] for idx in predicted_indices[i] if idx != 0])\n",
    "            true_word = ''.join([self.tokenizer_tokens.index_word[idx] for idx in self.y_val[i] if idx != 0])\n",
    "\n",
    "            print(f\"resultat : {pred_word} - attendue : {true_word}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 39ms/stepss: 6.0064 - accuracy: 2.9967\n",
      "\n",
      "Epoch 1:\n",
      "resultat : rgiargiargiargiargiargiargiargiacocococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococo - attendue : philophrosyne\n",
      "resultat : caiucococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococo - attendue : dike\n",
      "resultat : cocococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococo - attendue : asteria\n",
      "resultat : keakeachio pacococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococo - attendue : rhapso\n",
      "resultat : rgiargiargiargiacococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococococo - attendue : astraea\n",
      "1/1 [==============================] - 6s 6s/step - loss: 6.0064 - accuracy: 2.9967e-05 - val_loss: 5.9948 - val_accuracy: 0.0607\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 41ms/stepss: 5.9948 - accuracy: 0.\n",
      "\n",
      "Epoch 2:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 5.9948 - accuracy: 0.0534 - val_loss: 5.9834 - val_accuracy: 0.9823\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 41ms/stepss: 5.9833 - accuracy: 0.\n",
      "\n",
      "Epoch 3:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 5.9833 - accuracy: 0.9826 - val_loss: 5.9704 - val_accuracy: 0.9823\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 41ms/stepss: 5.9703 - accuracy: 0.\n",
      "\n",
      "Epoch 4:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 5.9703 - accuracy: 0.9826 - val_loss: 5.9540 - val_accuracy: 0.9823\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 42ms/stepss: 5.9538 - accuracy: 0.\n",
      "\n",
      "Epoch 5:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 5.9538 - accuracy: 0.9826 - val_loss: 5.9324 - val_accuracy: 0.9823\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 43ms/stepss: 5.9321 - accuracy: 0.\n",
      "\n",
      "Epoch 6:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 5.9321 - accuracy: 0.9826 - val_loss: 5.9020 - val_accuracy: 0.9823\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 44ms/stepss: 5.9016 - accuracy: 0.\n",
      "\n",
      "Epoch 7:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 5.9016 - accuracy: 0.9826 - val_loss: 5.8549 - val_accuracy: 0.9823\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 43ms/stepss: 5.8543 - accuracy: 0.\n",
      "\n",
      "Epoch 8:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 5.8543 - accuracy: 0.9826 - val_loss: 5.7715 - val_accuracy: 0.9823\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 42ms/stepss: 5.7704 - accuracy: 0.\n",
      "\n",
      "Epoch 9:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 5.7704 - accuracy: 0.9826 - val_loss: 5.5943 - val_accuracy: 0.9823\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 42ms/stepss: 5.5921 - accuracy: 0.\n",
      "\n",
      "Epoch 10:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 5.5921 - accuracy: 0.9826 - val_loss: 5.2185 - val_accuracy: 0.9823\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 44ms/stepss: 5.2146 - accuracy: 0.\n",
      "\n",
      "Epoch 11:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 5.2146 - accuracy: 0.9826 - val_loss: 4.7500 - val_accuracy: 0.9823\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 43ms/stepss: 4.7467 - accuracy: 0.\n",
      "\n",
      "Epoch 12:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 4.7467 - accuracy: 0.9826 - val_loss: 4.3044 - val_accuracy: 0.9823\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 42ms/stepss: 4.3016 - accuracy: 0.\n",
      "\n",
      "Epoch 13:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 4.3016 - accuracy: 0.9826 - val_loss: 3.8867 - val_accuracy: 0.9823\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 44ms/stepss: 3.8840 - accuracy: 0.\n",
      "\n",
      "Epoch 14:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.8840 - accuracy: 0.9826 - val_loss: 3.4872 - val_accuracy: 0.9823\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 43ms/stepss: 3.4846 - accuracy: 0.\n",
      "\n",
      "Epoch 15:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.4846 - accuracy: 0.9826 - val_loss: 3.0905 - val_accuracy: 0.9823\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 44ms/stepss: 3.0877 - accuracy: 0.\n",
      "\n",
      "Epoch 16:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.0877 - accuracy: 0.9826 - val_loss: 2.6972 - val_accuracy: 0.9823\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 43ms/stepss: 2.6943 - accuracy: 0.\n",
      "\n",
      "Epoch 17:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.6943 - accuracy: 0.9826 - val_loss: 2.2962 - val_accuracy: 0.9823\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 51ms/stepss: 2.2931 - accuracy: 0.\n",
      "\n",
      "Epoch 18:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.2931 - accuracy: 0.9826 - val_loss: 1.8961 - val_accuracy: 0.9823\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 46ms/stepss: 1.8927 - accuracy: 0.\n",
      "\n",
      "Epoch 19:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.8927 - accuracy: 0.9826 - val_loss: 1.5008 - val_accuracy: 0.9823\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 50ms/stepss: 1.4970 - accuracy: 0.\n",
      "\n",
      "Epoch 20:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.4970 - accuracy: 0.9826 - val_loss: 1.1420 - val_accuracy: 0.9823\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 61ms/stepss: 1.1379 - accuracy: 0.\n",
      "\n",
      "Epoch 21:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.1379 - accuracy: 0.9826 - val_loss: 0.8383 - val_accuracy: 0.9823\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 45ms/stepss: 0.8338 - accuracy: 0.\n",
      "\n",
      "Epoch 22:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8338 - accuracy: 0.9826 - val_loss: 0.6072 - val_accuracy: 0.9823\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 46ms/stepss: 0.6025 - accuracy: 0.\n",
      "\n",
      "Epoch 23:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6025 - accuracy: 0.9826 - val_loss: 0.4491 - val_accuracy: 0.9823\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 54ms/stepss: 0.4441 - accuracy: 0.\n",
      "\n",
      "Epoch 24:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4441 - accuracy: 0.9826 - val_loss: 0.3491 - val_accuracy: 0.9823\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 51ms/stepss: 0.3439 - accuracy: \n",
      "\n",
      "Epoch 25:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3439 - accuracy: 0.9826 - val_loss: 0.2880 - val_accuracy: 0.9823\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 50ms/stepss: 0.2825 - accuracy: 0.\n",
      "\n",
      "Epoch 26:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2825 - accuracy: 0.9826 - val_loss: 0.2502 - val_accuracy: 0.9823\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 67ms/stepss: 0.2445 - accuracy: \n",
      "\n",
      "Epoch 27:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2445 - accuracy: 0.9826 - val_loss: 0.2258 - val_accuracy: 0.9823\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 49ms/stepss: 0.2200 - accuracy: 0.\n",
      "\n",
      "Epoch 28:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2200 - accuracy: 0.9826 - val_loss: 0.2092 - val_accuracy: 0.9823\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 62ms/stepss: 0.2031 - accuracy: \n",
      "\n",
      "Epoch 29:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2031 - accuracy: 0.9826 - val_loss: 0.1971 - val_accuracy: 0.9823\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 47ms/stepss: 0.1908 - accuracy: 0.\n",
      "\n",
      "Epoch 30:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1908 - accuracy: 0.9826 - val_loss: 0.1879 - val_accuracy: 0.9823\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 58ms/stepss: 0.1814 - accuracy: \n",
      "\n",
      "Epoch 31:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1814 - accuracy: 0.9826 - val_loss: 0.1805 - val_accuracy: 0.9823\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 61ms/stepss: 0.1739 - accuracy: \n",
      "\n",
      "Epoch 32:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1739 - accuracy: 0.9826 - val_loss: 0.1744 - val_accuracy: 0.9823\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 48ms/stepss: 0.1676 - accuracy: 0.\n",
      "\n",
      "Epoch 33:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1676 - accuracy: 0.9826 - val_loss: 0.1692 - val_accuracy: 0.9823\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 49ms/stepss: 0.1623 - accuracy: 0.\n",
      "\n",
      "Epoch 34:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1623 - accuracy: 0.9826 - val_loss: 0.1648 - val_accuracy: 0.9823\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 46ms/stepss: 0.1578 - accuracy: 0.\n",
      "\n",
      "Epoch 35:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1578 - accuracy: 0.9826 - val_loss: 0.1609 - val_accuracy: 0.9823\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 46ms/stepss: 0.1538 - accuracy: 0.\n",
      "\n",
      "Epoch 36:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1538 - accuracy: 0.9826 - val_loss: 0.1575 - val_accuracy: 0.9823\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 56ms/stepss: 0.1503 - accuracy: 0.\n",
      "\n",
      "Epoch 37:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1503 - accuracy: 0.9826 - val_loss: 0.1545 - val_accuracy: 0.9823\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 48ms/stepss: 0.1472 - accuracy: 0.\n",
      "\n",
      "Epoch 38:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1472 - accuracy: 0.9826 - val_loss: 0.1519 - val_accuracy: 0.9823\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 47ms/stepss: 0.1444 - accuracy: 0.\n",
      "\n",
      "Epoch 39:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1444 - accuracy: 0.9826 - val_loss: 0.1495 - val_accuracy: 0.9823\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 52ms/stepss: 0.1420 - accuracy: 0.\n",
      "\n",
      "Epoch 40:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1420 - accuracy: 0.9826 - val_loss: 0.1473 - val_accuracy: 0.9823\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 48ms/stepss: 0.1397 - accuracy: 0.\n",
      "\n",
      "Epoch 41:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1397 - accuracy: 0.9826 - val_loss: 0.1453 - val_accuracy: 0.9823\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 52ms/stepss: 0.1377 - accuracy: 0.\n",
      "\n",
      "Epoch 42:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1377 - accuracy: 0.9826 - val_loss: 0.1435 - val_accuracy: 0.9823\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 53ms/stepss: 0.1358 - accuracy: 0.\n",
      "\n",
      "Epoch 43:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1358 - accuracy: 0.9826 - val_loss: 0.1419 - val_accuracy: 0.9823\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 51ms/stepss: 0.1342 - accuracy: 0.\n",
      "\n",
      "Epoch 44:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1342 - accuracy: 0.9826 - val_loss: 0.1404 - val_accuracy: 0.9823\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 49ms/stepss: 0.1326 - accuracy: 0.\n",
      "\n",
      "Epoch 45:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1326 - accuracy: 0.9826 - val_loss: 0.1390 - val_accuracy: 0.9823\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 47ms/stepss: 0.1312 - accuracy: 0.\n",
      "\n",
      "Epoch 46:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1312 - accuracy: 0.9826 - val_loss: 0.1377 - val_accuracy: 0.9823\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 48ms/stepss: 0.1300 - accuracy: 0.\n",
      "\n",
      "Epoch 47:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1300 - accuracy: 0.9826 - val_loss: 0.1366 - val_accuracy: 0.9823\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 56ms/stepss: 0.1288 - accuracy: 0.\n",
      "\n",
      "Epoch 48:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1288 - accuracy: 0.9826 - val_loss: 0.1355 - val_accuracy: 0.9823\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 58ms/stepss: 0.1277 - accuracy: \n",
      "\n",
      "Epoch 49:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1277 - accuracy: 0.9826 - val_loss: 0.1345 - val_accuracy: 0.9823\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 56ms/stepss: 0.1267 - accuracy: \n",
      "\n",
      "Epoch 50:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1267 - accuracy: 0.9826 - val_loss: 0.1335 - val_accuracy: 0.9823\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 49ms/stepss: 0.1257 - accuracy: 0.\n",
      "\n",
      "Epoch 51:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1257 - accuracy: 0.9826 - val_loss: 0.1326 - val_accuracy: 0.9823\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 48ms/stepss: 0.1248 - accuracy: 0.\n",
      "\n",
      "Epoch 52:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1248 - accuracy: 0.9826 - val_loss: 0.1318 - val_accuracy: 0.9823\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 49ms/stepss: 0.1239 - accuracy: 0.\n",
      "\n",
      "Epoch 53:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1239 - accuracy: 0.9826 - val_loss: 0.1310 - val_accuracy: 0.9823\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 63ms/stepss: 0.1231 - accuracy: \n",
      "\n",
      "Epoch 54:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1231 - accuracy: 0.9826 - val_loss: 0.1303 - val_accuracy: 0.9823\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 48ms/stepss: 0.1224 - accuracy: 0.\n",
      "\n",
      "Epoch 55:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1224 - accuracy: 0.9826 - val_loss: 0.1296 - val_accuracy: 0.9823\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 51ms/stepss: 0.1216 - accuracy: 0.\n",
      "\n",
      "Epoch 56:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1216 - accuracy: 0.9826 - val_loss: 0.1289 - val_accuracy: 0.9823\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 48ms/stepss: 0.1210 - accuracy: 0.\n",
      "\n",
      "Epoch 57:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1210 - accuracy: 0.9826 - val_loss: 0.1283 - val_accuracy: 0.9823\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 47ms/stepss: 0.1203 - accuracy: 0.\n",
      "\n",
      "Epoch 58:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1203 - accuracy: 0.9826 - val_loss: 0.1277 - val_accuracy: 0.9823\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 48ms/stepss: 0.1197 - accuracy: 0.\n",
      "\n",
      "Epoch 59:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1197 - accuracy: 0.9826 - val_loss: 0.1271 - val_accuracy: 0.9823\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 48ms/stepss: 0.1191 - accuracy: 0.\n",
      "\n",
      "Epoch 60:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1191 - accuracy: 0.9826 - val_loss: 0.1265 - val_accuracy: 0.9823\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 49ms/stepss: 0.1185 - accuracy: 0.\n",
      "\n",
      "Epoch 61:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1185 - accuracy: 0.9826 - val_loss: 0.1260 - val_accuracy: 0.9823\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 48ms/stepss: 0.1180 - accuracy: 0.\n",
      "\n",
      "Epoch 62:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1180 - accuracy: 0.9826 - val_loss: 0.1255 - val_accuracy: 0.9823\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 67ms/stepss: 0.1175 - accuracy: \n",
      "\n",
      "Epoch 63:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1175 - accuracy: 0.9826 - val_loss: 0.1250 - val_accuracy: 0.9823\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 49ms/stepss: 0.1170 - accuracy: 0.\n",
      "\n",
      "Epoch 64:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1170 - accuracy: 0.9826 - val_loss: 0.1245 - val_accuracy: 0.9823\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 54ms/stepss: 0.1165 - accuracy: \n",
      "\n",
      "Epoch 65:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1165 - accuracy: 0.9826 - val_loss: 0.1241 - val_accuracy: 0.9823\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 64ms/stepss: 0.1160 - accuracy: \n",
      "\n",
      "Epoch 66:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1160 - accuracy: 0.9826 - val_loss: 0.1237 - val_accuracy: 0.9823\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 51ms/stepss: 0.1156 - accuracy: \n",
      "\n",
      "Epoch 67:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1156 - accuracy: 0.9826 - val_loss: 0.1232 - val_accuracy: 0.9823\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 52ms/stepss: 0.1151 - accuracy: 0.\n",
      "\n",
      "Epoch 68:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1151 - accuracy: 0.9826 - val_loss: 0.1228 - val_accuracy: 0.9823\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 61ms/stepss: 0.1147 - accuracy: \n",
      "\n",
      "Epoch 69:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1147 - accuracy: 0.9826 - val_loss: 0.1224 - val_accuracy: 0.9823\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 57ms/stepss: 0.1143 - accuracy: \n",
      "\n",
      "Epoch 70:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1143 - accuracy: 0.9826 - val_loss: 0.1220 - val_accuracy: 0.9823\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 50ms/stepss: 0.1139 - accuracy: 0.\n",
      "\n",
      "Epoch 71:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1139 - accuracy: 0.9826 - val_loss: 0.1217 - val_accuracy: 0.9823\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 51ms/stepss: 0.1135 - accuracy: 0.\n",
      "\n",
      "Epoch 72:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1135 - accuracy: 0.9826 - val_loss: 0.1213 - val_accuracy: 0.9823\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 53ms/stepss: 0.1131 - accuracy: 0.\n",
      "\n",
      "Epoch 73:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1131 - accuracy: 0.9826 - val_loss: 0.1210 - val_accuracy: 0.9823\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 55ms/stepss: 0.1128 - accuracy: \n",
      "\n",
      "Epoch 74:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1128 - accuracy: 0.9826 - val_loss: 0.1206 - val_accuracy: 0.9823\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 51ms/stepss: 0.1124 - accuracy: 0.\n",
      "\n",
      "Epoch 75:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1124 - accuracy: 0.9826 - val_loss: 0.1203 - val_accuracy: 0.9823\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 50ms/stepss: 0.1120 - accuracy: 0.\n",
      "\n",
      "Epoch 76:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1120 - accuracy: 0.9826 - val_loss: 0.1199 - val_accuracy: 0.9823\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 47ms/stepss: 0.1117 - accuracy: 0.\n",
      "\n",
      "Epoch 77:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1117 - accuracy: 0.9826 - val_loss: 0.1196 - val_accuracy: 0.9823\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 49ms/stepss: 0.1113 - accuracy: 0.\n",
      "\n",
      "Epoch 78:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1113 - accuracy: 0.9826 - val_loss: 0.1193 - val_accuracy: 0.9823\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 48ms/stepss: 0.1110 - accuracy: 0.\n",
      "\n",
      "Epoch 79:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1110 - accuracy: 0.9826 - val_loss: 0.1190 - val_accuracy: 0.9823\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 47ms/stepss: 0.1107 - accuracy: 0.\n",
      "\n",
      "Epoch 80:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1107 - accuracy: 0.9826 - val_loss: 0.1187 - val_accuracy: 0.9823\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 49ms/stepss: 0.1104 - accuracy: 0.\n",
      "\n",
      "Epoch 81:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1104 - accuracy: 0.9826 - val_loss: 0.1184 - val_accuracy: 0.9823\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 48ms/stepss: 0.1100 - accuracy: 0.\n",
      "\n",
      "Epoch 82:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1100 - accuracy: 0.9826 - val_loss: 0.1181 - val_accuracy: 0.9823\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 53ms/stepss: 0.1097 - accuracy: 0.\n",
      "\n",
      "Epoch 83:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1097 - accuracy: 0.9826 - val_loss: 0.1179 - val_accuracy: 0.9823\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 50ms/stepss: 0.1094 - accuracy: 0.\n",
      "\n",
      "Epoch 84:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1094 - accuracy: 0.9826 - val_loss: 0.1176 - val_accuracy: 0.9823\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 59ms/stepss: 0.1092 - accuracy: \n",
      "\n",
      "Epoch 85:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1092 - accuracy: 0.9826 - val_loss: 0.1174 - val_accuracy: 0.9823\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 54ms/stepss: 0.1089 - accuracy: 0.\n",
      "\n",
      "Epoch 86:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1089 - accuracy: 0.9826 - val_loss: 0.1171 - val_accuracy: 0.9823\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 50ms/stepss: 0.1086 - accuracy: 0.\n",
      "\n",
      "Epoch 87:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1086 - accuracy: 0.9826 - val_loss: 0.1169 - val_accuracy: 0.9823\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 51ms/stepss: 0.1084 - accuracy: 0.\n",
      "\n",
      "Epoch 88:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1084 - accuracy: 0.9826 - val_loss: 0.1167 - val_accuracy: 0.9823\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 59ms/stepss: 0.1081 - accuracy: \n",
      "\n",
      "Epoch 89:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1081 - accuracy: 0.9826 - val_loss: 0.1165 - val_accuracy: 0.9823\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 56ms/stepss: 0.1079 - accuracy: \n",
      "\n",
      "Epoch 90:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1079 - accuracy: 0.9826 - val_loss: 0.1163 - val_accuracy: 0.9823\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 49ms/stepss: 0.1077 - accuracy: 0.\n",
      "\n",
      "Epoch 91:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1077 - accuracy: 0.9826 - val_loss: 0.1162 - val_accuracy: 0.9823\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 47ms/stepss: 0.1075 - accuracy: 0.\n",
      "\n",
      "Epoch 92:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1075 - accuracy: 0.9826 - val_loss: 0.1160 - val_accuracy: 0.9823\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 49ms/stepss: 0.1073 - accuracy: 0.\n",
      "\n",
      "Epoch 93:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1073 - accuracy: 0.9826 - val_loss: 0.1159 - val_accuracy: 0.9823\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 63ms/stepss: 0.1072 - accuracy: \n",
      "\n",
      "Epoch 94:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1072 - accuracy: 0.9826 - val_loss: 0.1157 - val_accuracy: 0.9823\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 47ms/stepss: 0.1070 - accuracy: 0.\n",
      "\n",
      "Epoch 95:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1070 - accuracy: 0.9826 - val_loss: 0.1156 - val_accuracy: 0.9823\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 47ms/stepss: 0.1068 - accuracy: 0.\n",
      "\n",
      "Epoch 96:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1068 - accuracy: 0.9826 - val_loss: 0.1154 - val_accuracy: 0.9823\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 50ms/stepss: 0.1067 - accuracy: 0.\n",
      "\n",
      "Epoch 97:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1067 - accuracy: 0.9826 - val_loss: 0.1153 - val_accuracy: 0.9823\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 71ms/stepss: 0.1065 - accuracy: \n",
      "\n",
      "Epoch 98:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1065 - accuracy: 0.9826 - val_loss: 0.1152 - val_accuracy: 0.9823\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 54ms/stepss: 0.1063 - accuracy: \n",
      "\n",
      "Epoch 99:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1063 - accuracy: 0.9826 - val_loss: 0.1150 - val_accuracy: 0.9823\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 53ms/stepss: 0.1061 - accuracy: 0.\n",
      "\n",
      "Epoch 100:\n",
      "resultat :  - attendue : philophrosyne\n",
      "resultat :  - attendue : dike\n",
      "resultat :  - attendue : asteria\n",
      "resultat :  - attendue : rhapso\n",
      "resultat :  - attendue : astraea\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1061 - accuracy: 0.9826 - val_loss: 0.1149 - val_accuracy: 0.9823\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f0f28aa790>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df[\"description\"] = df[\"description\"].fillna(\"\")\n",
    "\n",
    "tokenizer_desc = Tokenizer()\n",
    "tokenizer_desc.fit_on_texts(df[\"description\"])\n",
    "X = tokenizer_desc.texts_to_sequences(df[\"description\"])\n",
    "\n",
    "tokenizer_tokens = Tokenizer(char_level=True)\n",
    "tokenizer_tokens.fit_on_texts(df[\"tokens\"])\n",
    "y = tokenizer_tokens.texts_to_sequences(df[\"tokens\"])\n",
    "\n",
    "maxlen = max(max(len(seq) for seq in X), max(len(seq) for seq in y))\n",
    "X_normalized = pad_sequences(X, maxlen=maxlen, padding=\"post\")\n",
    "y_normalized = pad_sequences(y, maxlen=maxlen, padding=\"post\")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_normalized, y_normalized, test_size=0.2, random_state=42)\n",
    "\n",
    "vocab_size_desc = len(tokenizer_desc.word_index) + 1\n",
    "vocab_size_tokens = len(tokenizer_tokens.word_index) + 1 \n",
    "\n",
    "embedding_dim = 20\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=vocab_size_desc, output_dim=embedding_dim, input_length=maxlen),\n",
    "    LSTM(128, return_sequences=True),\n",
    "    Dense(64, activation=\"relu\"),\n",
    "    Dense(vocab_size_tokens, activation=\"softmax\") \n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "prediction_logger = PredictionLogger(X_val, y_val, tokenizer_tokens)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=1000, validation_data=(X_val, y_val), callbacks=[prediction_logger])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 59ms/step - loss: 0.1149 - accuracy: 0.9823\n",
      "Test Loss: 0.11486048996448517\n",
      "Test Accuracy: 0.9823093414306641\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Théoriquement, les resultats sont bons , mais concrètement, c'est catastrophique. Les prédictions sont jugées correctes quand elles sont vides, alors que ce n'est pas le cas.\\nPuisque toutes les descriptions comportent trop de mots unique, le modèle n'arrive pas à généraliser. Il manque trop de données pour faire quoi que ce soit.\\n\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss}\")\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "''' Théoriquement, les resultats sont bons , mais concrètement, c'est catastrophique. Les prédictions sont jugées correctes quand elles sont vides, alors que ce n'est pas le cas.\n",
    "Puisque toutes les descriptions comportent trop de mots unique, le modèle n'arrive pas à généraliser. Il manque trop de données pour faire quoi que ce soit.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n",
      "IA prédiction : \n"
     ]
    }
   ],
   "source": [
    "\n",
    "def predict_name(description):\n",
    "    seq = tokenizer_desc.texts_to_sequences([description])  \n",
    "    seq_padded = pad_sequences(seq, maxlen=maxlen, padding=\"post\")  \n",
    "\n",
    "    predicted = model.predict(seq_padded, verbose=0)\n",
    "\n",
    "    predicted_indices = np.argmax(predicted, axis=-1)[0]\n",
    "    print(predicted_indices)\n",
    "    syllables = [tokenizer_tokens.index_word[i] for i in predicted_indices if i != 0]\n",
    "\n",
    "    predicted_name = ''.join(syllables)\n",
    "    return predicted_name\n",
    "\n",
    "description = \"god of the sky, thunder, and justice\"\n",
    "predicted_name = predict_name(description)\n",
    "print(f\"IA prédiction : {predicted_name}\")\n",
    "# le résultat est bon selon le modèle, mais pas pour l'utilisateur"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
